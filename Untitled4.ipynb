{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMT/Xj4t3lDmgtAf8JvY42h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushi3/Python/blob/master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b06c9Et_OkMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "bab80d9e-7d46-4211-9b88-b682b261afc5"
      },
      "source": [
        "!wget https://chromedriver.storage.googleapis.com/2.43/chromedriver_linux64.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 06:01:06--  https://chromedriver.storage.googleapis.com/2.43/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c04::80\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4083255 (3.9M) [application/zip]\n",
            "Saving to: ‘chromedriver_linux64.zip’\n",
            "\n",
            "\rchromedriver_linux6   0%[                    ]       0  --.-KB/s               \rchromedriver_linux6 100%[===================>]   3.89M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-03-18 06:01:07 (172 MB/s) - ‘chromedriver_linux64.zip’ saved [4083255/4083255]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwELBAUiO0od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip chromedriver_linux64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYNS-cTqO6s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ./chromedriver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXawdznKP7Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install selenium\n",
        "!pip install lxml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_0iY43CVhvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pjreddie/darknet\n",
        "%cd darknet\n",
        "!make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mh8orAkV4Fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19ead05c-f01d-4eca-b817-d7bcf5397b81"
      },
      "source": [
        "! ./darknet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ./darknet <function>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK0DKQ0OWb0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WGOTg9IWj8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ac9732a2-3d3b-4bed-e657-c2fea11ea374"
      },
      "source": [
        "!cat /usr/local/lib/python3.6/dist-packages/external/local_config_cuda/cuda/cuda/cuda_config.h |\\\n",
        "grep TF_CUDA_VERSION"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: /usr/local/lib/python3.6/dist-packages/external/local_config_cuda/cuda/cuda/cuda_config.h: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0SmB0qWowg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "dc00c163-e276-4ba3-e286-aa29525d8cf6"
      },
      "source": [
        "!pip install mxnet-cu80"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu80\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/35bd08de97e7025dc65a4087ac08b6e87fa537d17cdaa14993f5db4cbdc5/mxnet_cu80-1.5.0-py2.py3-none-manylinux1_x86_64.whl (372.1MB)\n",
            "\u001b[K     |████████████████████████████████| 372.1MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu80) (1.18.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu80) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu80) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu80) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu80) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu80) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet-cu80\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu80-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jaTNr9lW1BA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "61e5f5fd-79f0-42d4-8f1b-70743eda26f8"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 06:37:09--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   634KB/s    in 7m 3s   \n",
            "\n",
            "2020-03-18 06:44:14 (572 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBY3FnUqntny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/AntonMu/TrainYourOwnYOLO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXzBaIKMqUVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf Training_Images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "horyW4wlsxjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf Test_Image_Detection_Results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIouIe8PvFeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bfdb1c9-5d7b-4185-a592-3a15cd3ab78d"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TrainYourOwnYOLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEf46aJvJTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0592f516-83cf-4363-b707-5d64c44017e4"
      },
      "source": [
        "%cd 2_Training/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TrainYourOwnYOLO/2_Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6EVtX6PvNQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Download_and_Convert_YOLO_weights.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW84rbBdGefF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Image_Detection_Results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nKWrAek0Bor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "849245a6-e6ee-4082-eefc-ae04263c605b"
      },
      "source": [
        "!python Train_YOLO.py"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-18 08:51:36.588618: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-18 08:51:36.588848: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cf0a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-18 08:51:36.588901: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-18 08:51:36.591146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-18 08:51:36.665075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.665949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cf0bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-18 08:51:36.665987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-03-18 08:51:36.666141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.666864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-18 08:51:36.667163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-18 08:51:36.668999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-18 08:51:36.670753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-18 08:51:36.671073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-18 08:51:36.673199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-18 08:51:36.674505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-18 08:51:36.678840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-18 08:51:36.678943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.679674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.680395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-18 08:51:36.680472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-18 08:51:36.681989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-18 08:51:36.682047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-18 08:51:36.682063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-18 08:51:36.682203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.683139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-18 08:51:36.683990: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-18 08:51:36.684087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Create YOLOv3 model with 9 anchors and 2 classes.\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "Load weights /content/TrainYourOwnYOLO/2_Training/src/keras_yolo3/yolo.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3351: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "8888888888888888888*********************************98888888888888888888888888888888888\n",
            "['/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(1).jpg 131,66,182,157,0 4,59,295,161,1 0,1,300,12,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(2).jpg 61,102,117,175,0 9,88,189,177,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(3).jpg 145,59,186,119,0 3,57,307,122,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/2586.jpg 329,102,464,439,0 18,102,790,426,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(4).jpg 122,111,150,152,0 2,111,256,152,1 201,25,258,41,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(6).jpg 85,71,121,141,0 1,71,217,137,1 2,13,219,55,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download.jpg 374,174,551,490,0 5,179,875,485,1 7,0,879,36,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(1).jpg 25,57,182,112,0 0,54,273,116,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(2).jpg 61,64,103,152,0 5,52,192,175,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/download%20(5).jpg 142,19,164,136,0 2,20,299,136,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(4).jpg 161,49,193,114,0 3,52,321,98,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(3).jpg 99,77,138,129,0 2,66,257,127,1 1,0,259,19,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(5).jpg 127,74,156,145,0 41,70,278,144,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(6).jpg 129,63,173,112,0 6,58,326,134,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(7).jpg 118,67,146,103,0 0,68,262,102,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images.jpg 74,16,154,133,0 0,15,192,127,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0012.jpg 404,109,528,289,0 34,89,775,320,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/images%20(8).jpg 78,29,150,119,0 2,39,275,126,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0013.jpg 317,341,434,542,0 1,327,880,562,1 5,88,868,303,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0011.jpg 391,94,630,365,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0017.jpg 291,0,462,411,0 39,23,666,311,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0014.jpg 449,139,530,272,0 42,0,555,431,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0015.jpg 266,402,442,763,0 41,328,770,833,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0016.jpg 335,68,633,644,0 223,90,820,562,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0018.jpg 417,126,565,498,0 66,140,811,428,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0020.jpg 305,267,534,616,0 30,280,861,581,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0021.jpg 341,177,486,770,0 52,152,853,738,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0023.jpg 393,191,602,500,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0019.jpg 345,179,533,448,0 37,178,820,443,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0022.jpg 281,108,573,447,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0025.jpg 272,284,571,403,0 272,15,566,658,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0027.jpg 327,20,504,581,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0028.jpg 315,98,555,571,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0024.jpg 402,173,568,477,0 15,134,837,485,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0026.jpg 434,295,552,426,0 9,306,916,417,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0031.jpg 42,261,317,391,0 15,263,837,494,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0029.jpg 205,202,554,301,0 29,177,815,319,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0030.jpg 428,221,509,419,0 12,107,820,529,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0033.jpg 174,130,690,319,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0032.jpg 350,143,528,373,0 13,126,826,346,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0036.jpg 400,234,513,407,0 63,216,950,394,1\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0038.jpg 329,111,529,644,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0034.jpg 195,138,712,381,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0035.jpg 154,442,508,922,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/IMG-20200318-WA0037.jpg 255,3,540,486,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/Squat-defect-on-the-running-surface-or-ball-of-the-rail-head_Q320.jpg 75,53,271,210,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/stream_img.jpg 182,77,325,181,0\\n', '/content/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export/unnamed.jpg 81,18,244,148,0']\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Train on 44 samples, val on 4 samples, with batch size 32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/51\n",
            "2020-03-18 08:51:59.104310: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:51:59.201617: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:51:59.466440: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:51:59.829184: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:51:59.886607: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:52:01.601625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-18 08:52:06.383536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-18 08:52:12.306095: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:52:12.690080: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:52:12.943520: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "1/1 [==============================] - 21s 21s/step - loss: 10612.8799 - val_loss: 9101.4609\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 9613.3457 - val_loss: 8226.0781\n",
            "Epoch 3/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 8614.0615 - val_loss: 7288.2363\n",
            "Epoch 4/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 7728.4492 - val_loss: 6661.2124\n",
            "Epoch 5/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 7009.1802 - val_loss: 5849.9673\n",
            "Epoch 6/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6287.8623 - val_loss: 5591.1948\n",
            "Epoch 7/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5607.9907 - val_loss: 5022.7671\n",
            "Epoch 8/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5083.1143 - val_loss: 4409.2622\n",
            "Epoch 9/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4564.3345 - val_loss: 3905.7659\n",
            "Epoch 10/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4069.9348 - val_loss: 3495.5784\n",
            "Epoch 11/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3684.6118 - val_loss: 3355.7773\n",
            "Epoch 12/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3327.3191 - val_loss: 2770.7373\n",
            "Epoch 13/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3121.4622 - val_loss: 2507.3567\n",
            "Epoch 14/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2715.4863 - val_loss: 2492.8860\n",
            "Epoch 15/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2465.8284 - val_loss: 2146.0193\n",
            "Epoch 16/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2349.1355 - val_loss: 1930.1083\n",
            "Epoch 17/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2170.5635 - val_loss: 1930.3599\n",
            "Epoch 18/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1942.2876 - val_loss: 1785.0537\n",
            "Epoch 19/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1817.0314 - val_loss: 1658.3453\n",
            "Epoch 20/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1571.1294 - val_loss: 1299.1368\n",
            "Epoch 21/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1459.0266 - val_loss: 1282.7758\n",
            "Epoch 22/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1369.4907 - val_loss: 1290.4160\n",
            "Epoch 23/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1331.6448 - val_loss: 918.7238\n",
            "Epoch 24/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1184.9980 - val_loss: 985.4319\n",
            "Epoch 25/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1046.0297 - val_loss: 899.5201\n",
            "Epoch 26/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1061.0809 - val_loss: 885.1600\n",
            "Epoch 27/51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 957.2786 - val_loss: 842.9734\n",
            "Epoch 28/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 912.5563 - val_loss: 793.0602\n",
            "Epoch 29/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 916.1957 - val_loss: 735.1008\n",
            "Epoch 30/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 772.0298 - val_loss: 652.9039\n",
            "Epoch 31/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 754.4805 - val_loss: 611.0791\n",
            "Epoch 32/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 646.8607 - val_loss: 509.1502\n",
            "Epoch 33/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 589.8424 - val_loss: 571.1036\n",
            "Epoch 34/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 609.5084 - val_loss: 467.5271\n",
            "Epoch 35/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 611.2483 - val_loss: 437.5838\n",
            "Epoch 36/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 585.4396 - val_loss: 496.2759\n",
            "Epoch 37/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 528.8392 - val_loss: 423.7211\n",
            "Epoch 38/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 510.7795 - val_loss: 407.5557\n",
            "Epoch 39/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 503.2348 - val_loss: 446.7425\n",
            "Epoch 40/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 500.4464 - val_loss: 425.0710\n",
            "Epoch 41/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 464.9818 - val_loss: 412.5521\n",
            "Epoch 42/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 394.8829 - val_loss: 397.5820\n",
            "Epoch 43/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 448.8642 - val_loss: 355.5646\n",
            "Epoch 44/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 429.7490 - val_loss: 365.1220\n",
            "Epoch 45/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 412.8635 - val_loss: 319.1568\n",
            "Epoch 46/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 365.2111 - val_loss: 328.3948\n",
            "Epoch 47/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 359.9513 - val_loss: 303.1578\n",
            "Epoch 48/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 354.1157 - val_loss: 310.3097\n",
            "Epoch 49/51\n",
            "1/1 [==============================] - 5s 5s/step - loss: 367.8200 - val_loss: 273.4008\n",
            "Epoch 50/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 359.8997 - val_loss: 300.2733\n",
            "Epoch 51/51\n",
            "1/1 [==============================] - 4s 4s/step - loss: 329.8958 - val_loss: 288.6254\n",
            "Unfreeze all layers.\n",
            "Train on 44 samples, val on 4 samples, with batch size 4.\n",
            "Epoch 52/102\n",
            "2020-03-18 08:56:49.856422: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:56:50.537372: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:56:52.890042: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:56:53.824538: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:56:54.036866: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "10/11 [==========================>...] - ETA: 2s - loss: 139.37842020-03-18 08:57:09.102442: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:57:09.199058: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-03-18 08:57:09.328842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "11/11 [==============================] - 25s 2s/step - loss: 135.5846 - val_loss: 153.9381\n",
            "Epoch 53/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 77.9267 - val_loss: 86.4104\n",
            "Epoch 54/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 63.2364 - val_loss: 67.7627\n",
            "Epoch 55/102\n",
            "11/11 [==============================] - 10s 900ms/step - loss: 53.8650 - val_loss: 51.0448\n",
            "Epoch 56/102\n",
            "11/11 [==============================] - 10s 905ms/step - loss: 47.7240 - val_loss: 39.9027\n",
            "Epoch 57/102\n",
            "11/11 [==============================] - 10s 905ms/step - loss: 42.4447 - val_loss: 37.8928\n",
            "Epoch 58/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 39.9973 - val_loss: 35.1672\n",
            "Epoch 59/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 36.7617 - val_loss: 32.5229\n",
            "Epoch 60/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 34.9179 - val_loss: 33.0741\n",
            "Epoch 61/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 33.1031 - val_loss: 29.6770\n",
            "Epoch 62/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 32.7809 - val_loss: 29.7848\n",
            "Epoch 63/102\n",
            "11/11 [==============================] - 10s 906ms/step - loss: 31.4457 - val_loss: 28.8461\n",
            "Epoch 64/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 30.0440 - val_loss: 28.9082\n",
            "Epoch 65/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 29.0157 - val_loss: 28.6660\n",
            "Epoch 66/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 28.6791 - val_loss: 27.9127\n",
            "Epoch 67/102\n",
            "11/11 [==============================] - 10s 904ms/step - loss: 28.3807 - val_loss: 26.0697\n",
            "Epoch 68/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 26.3977 - val_loss: 25.4836\n",
            "Epoch 69/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 26.4260 - val_loss: 25.3897\n",
            "Epoch 70/102\n",
            "11/11 [==============================] - 10s 904ms/step - loss: 24.9686 - val_loss: 24.3850\n",
            "Epoch 71/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 24.5341 - val_loss: 27.2065\n",
            "Epoch 72/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 24.3170 - val_loss: 24.7642\n",
            "Epoch 73/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 23.5988 - val_loss: 25.4379\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 74/102\n",
            "11/11 [==============================] - 10s 900ms/step - loss: 24.3736 - val_loss: 22.2814\n",
            "Epoch 75/102\n",
            "11/11 [==============================] - 10s 902ms/step - loss: 23.4282 - val_loss: 21.5650\n",
            "Epoch 76/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 22.2588 - val_loss: 22.3679\n",
            "Epoch 77/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 22.6244 - val_loss: 23.8118\n",
            "Epoch 78/102\n",
            "11/11 [==============================] - 10s 904ms/step - loss: 22.5844 - val_loss: 24.1115\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 79/102\n",
            "11/11 [==============================] - 10s 903ms/step - loss: 22.1049 - val_loss: 20.8363\n",
            "Epoch 80/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 23.4083 - val_loss: 21.5030\n",
            "Epoch 81/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 23.2653 - val_loss: 21.6604\n",
            "Epoch 82/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 22.2541 - val_loss: 22.6836\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 83/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 22.4904 - val_loss: 21.4417\n",
            "Epoch 84/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 22.4773 - val_loss: 22.1650\n",
            "Epoch 85/102\n",
            "11/11 [==============================] - 10s 898ms/step - loss: 22.6076 - val_loss: 21.9577\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 86/102\n",
            "11/11 [==============================] - 10s 900ms/step - loss: 22.9864 - val_loss: 22.0085\n",
            "Epoch 87/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 22.2913 - val_loss: 20.5850\n",
            "Epoch 88/102\n",
            "11/11 [==============================] - 10s 904ms/step - loss: 22.8410 - val_loss: 22.0078\n",
            "Epoch 89/102\n",
            "11/11 [==============================] - 10s 905ms/step - loss: 22.5625 - val_loss: 22.6480\n",
            "Epoch 90/102\n",
            "11/11 [==============================] - 10s 900ms/step - loss: 23.5854 - val_loss: 20.6102\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 91/102\n",
            "11/11 [==============================] - 10s 896ms/step - loss: 21.6086 - val_loss: 20.8366\n",
            "Epoch 92/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 22.7021 - val_loss: 22.3271\n",
            "Epoch 93/102\n",
            "11/11 [==============================] - 10s 901ms/step - loss: 23.4237 - val_loss: 23.7787\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 94/102\n",
            "11/11 [==============================] - 10s 898ms/step - loss: 22.3276 - val_loss: 21.0294\n",
            "Epoch 95/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 22.7628 - val_loss: 22.6834\n",
            "Epoch 96/102\n",
            "11/11 [==============================] - 10s 886ms/step - loss: 22.1010 - val_loss: 21.6519\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 97/102\n",
            "11/11 [==============================] - 10s 899ms/step - loss: 22.5418 - val_loss: 22.2094\n",
            "Epoch 00097: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSSDdEDb47pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "061d1ca6-3351-418a-8e45-4af751d359b8"
      },
      "source": [
        "%cd 3_Inference/"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TrainYourOwnYOLO/3_Inference\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcXnJ3Ws5GSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3be61b61-f951-470f-b995-463fc39be7be"
      },
      "source": [
        "!python Detector.py"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "/content/TrainYourOwnYOLO/Data/Model_Weights/trained_weights_final.h5 model, anchors, and classes loaded in 11.49sec.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Found 2 input labels: ['crack', 'track'] ...\n",
            "Found 48 input images: ['images (2).jpg', 'IMG-20200318-WA0037.jpg', 'IMG-20200318-WA0011.jpg', 'IMG-20200318-WA0026.jpg', 'IMG-20200318-WA0021.jpg'] ...\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (2).jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "track 0.81 (0, 71) (259, 157)\n",
            "Time spent: 2.673sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0037.jpg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0011.jpg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0026.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "track 0.90 (0, 300) (916, 413)\n",
            "Time spent: 0.105sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0021.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.69 (0, 95) (873, 761)\n",
            "crack 0.28 (333, 214) (501, 715)\n",
            "Time spent: 0.107sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0028.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.44 (83, 19) (747, 612)\n",
            "crack 0.89 (307, 133) (540, 570)\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0015.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "track 0.61 (4, 379) (812, 814)\n",
            "Time spent: 0.107sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (4).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.60 (215, 27) (248, 40)\n",
            "track 0.66 (11, 112) (253, 148)\n",
            "crack 0.42 (124, 113) (146, 149)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/stream_img.jpg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0033.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "crack 0.67 (130, 26) (633, 397)\n",
            "Time spent: 0.100sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0020.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.92 (28, 255) (880, 606)\n",
            "crack 0.44 (256, 272) (619, 579)\n",
            "Time spent: 0.109sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (3).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.89 (0, 42) (311, 113)\n",
            "crack 0.51 (143, 30) (186, 141)\n",
            "Time spent: 0.096sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/2586.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.85 (23, 85) (793, 457)\n",
            "crack 0.36 (323, 120) (476, 419)\n",
            "Time spent: 0.103sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.40 (78, 38) (206, 122)\n",
            "track 0.61 (11, 56) (298, 100)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0014.jpg\n",
            "(416, 416, 3)\n",
            "Found 0 boxes for img\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0029.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "track 0.67 (96, 179) (756, 305)\n",
            "Time spent: 0.101sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0017.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.89 (101, 0) (683, 369)\n",
            "crack 0.60 (282, 0) (455, 434)\n",
            "Time spent: 0.100sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (1).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.96 (0, 57) (300, 153)\n",
            "crack 0.36 (73, 60) (231, 156)\n",
            "crack 0.88 (133, 58) (176, 162)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0034.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "crack 0.53 (134, 109) (663, 378)\n",
            "Time spent: 0.100sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0013.jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.80 (0, 328) (880, 557)\n",
            "track 0.90 (0, 65) (880, 281)\n",
            "crack 0.61 (291, 290) (434, 594)\n",
            "Time spent: 0.106sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (5).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.90 (21, 21) (283, 136)\n",
            "crack 0.90 (139, 19) (169, 137)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0024.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.92 (30, 155) (870, 488)\n",
            "crack 0.51 (403, 130) (561, 538)\n",
            "Time spent: 0.105sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0016.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.28 (192, 0) (763, 670)\n",
            "crack 0.67 (352, 161) (593, 516)\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (6).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.78 (1, 0) (220, 59)\n",
            "track 0.97 (0, 67) (220, 131)\n",
            "crack 0.40 (84, 53) (122, 153)\n",
            "Time spent: 0.099sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/download (2).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.71 (14, 81) (175, 186)\n",
            "crack 0.30 (62, 95) (112, 178)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0018.jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.79 (73, 87) (845, 505)\n",
            "crack 0.28 (388, 142) (596, 474)\n",
            "crack 0.82 (422, 72) (537, 547)\n",
            "Time spent: 0.105sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (4).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.65 (4, 52) (324, 100)\n",
            "crack 0.47 (163, 51) (194, 120)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (6).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.49 (38, 45) (288, 121)\n",
            "track 0.58 (0, 33) (326, 154)\n",
            "crack 0.32 (120, 49) (168, 121)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0023.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.77 (25, 186) (888, 486)\n",
            "crack 0.57 (383, 174) (642, 507)\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (5).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.69 (71, 66) (232, 137)\n",
            "crack 0.32 (123, 84) (164, 141)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (3).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.77 (14, 40) (255, 143)\n",
            "crack 0.86 (126, 36) (154, 145)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (8).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.92 (0, 38) (275, 108)\n",
            "crack 0.40 (64, 27) (168, 120)\n",
            "crack 0.47 (34, 0) (156, 145)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (7).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.48 (11, 66) (256, 107)\n",
            "crack 0.30 (112, 70) (158, 107)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0036.jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.36 (285, 183) (609, 422)\n",
            "track 0.77 (157, 219) (817, 381)\n",
            "crack 0.55 (434, 243) (499, 388)\n",
            "Time spent: 0.109sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/Squat-defect-on-the-running-surface-or-ball-of-the-rail-head_Q320.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "crack 0.36 (0, 42) (233, 218)\n",
            "crack 0.76 (105, 59) (260, 197)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images (1).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.25 (7, 17) (248, 100)\n",
            "track 0.77 (0, 54) (259, 130)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0038.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.66 (45, 140) (866, 630)\n",
            "crack 0.41 (326, 17) (543, 680)\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0019.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.73 (33, 172) (787, 444)\n",
            "crack 0.55 (341, 180) (582, 449)\n",
            "Time spent: 0.108sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0027.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.50 (3, 0) (851, 603)\n",
            "crack 0.73 (310, 0) (532, 596)\n",
            "Time spent: 0.103sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/unnamed.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.77 (6, 18) (292, 146)\n",
            "crack 0.35 (111, 0) (229, 168)\n",
            "Time spent: 0.097sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/images.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.79 (0, 57) (257, 136)\n",
            "crack 0.27 (128, 70) (173, 138)\n",
            "Time spent: 0.098sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0012.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.75 (3, 62) (839, 363)\n",
            "crack 0.27 (381, 124) (540, 293)\n",
            "Time spent: 0.101sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0022.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "crack 0.77 (201, 103) (657, 443)\n",
            "Time spent: 0.100sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0031.jpg\n",
            "(416, 416, 3)\n",
            "Found 1 boxes for img\n",
            "track 0.80 (0, 241) (853, 474)\n",
            "Time spent: 0.103sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0032.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.75 (4, 91) (856, 354)\n",
            "crack 0.74 (375, 147) (505, 336)\n",
            "Time spent: 0.104sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0035.jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "track 0.29 (33, 392) (565, 979)\n",
            "crack 0.44 (33, 392) (565, 979)\n",
            "crack 0.44 (200, 483) (383, 906)\n",
            "Time spent: 0.105sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0030.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.73 (76, 74) (766, 507)\n",
            "crack 0.63 (414, 180) (517, 437)\n",
            "Time spent: 0.102sec\n",
            "/content/TrainYourOwnYOLO/Data/Source_Images/Test_Images/IMG-20200318-WA0025.jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "track 0.69 (339, 0) (529, 660)\n",
            "crack 0.40 (343, 232) (539, 418)\n",
            "Time spent: 0.106sec\n",
            "Processed 48 images in 8.8sec - 5.5FPS\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}